"""
UNIQLO å•†å“çˆ¬èŸ²
å¾ UNIQLO å°ç£å®˜ç¶²çˆ¬å–å•†å“è³‡æ–™ä¸¦å„²å­˜ç‚º CSV

è¼¸å‡º: init/uniqlo_raw.csv
æ¬„ä½: sku, name, price, image_url
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
from typing import List, Dict

# é…ç½®
BASE_URL = "https://www.uniqlo.com/tw/zh_TW"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7",
    "Referer": "https://www.uniqlo.com/",
}


def crawl_category_page(
    category_url: str, max_items: int = 100, seen_skus: set = None
) -> List[Dict]:
    """
    çˆ¬å–æŒ‡å®šé¡åˆ¥é é¢çš„å•†å“åˆ—è¡¨

    Args:
        category_url: é¡åˆ¥é é¢URL
        max_items: æœ€å¤šçˆ¬å–æ•¸é‡
        seen_skus: å·²çˆ¬å–çš„ SKU é›†åˆï¼ˆç”¨æ–¼å»é‡ï¼‰

    Returns:
        å•†å“è³‡æ–™åˆ—è¡¨
    """
    if seen_skus is None:
        seen_skus = set()

    items = []
    skipped_count = 0

    try:
        response = requests.get(category_url, headers=HEADERS, timeout=30)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        # æ ¹æ“š UNIQLO ç¶²ç«™çµæ§‹æ‰¾å•†å“å€å¡Š
        product_blocks = soup.select(".product-tile")  # éœ€æ ¹æ“šå¯¦éš›ç¶²ç«™èª¿æ•´

        for block in product_blocks[:max_items]:
            try:
                # æå– SKU
                sku = block.get("data-product-id", "")

                # ğŸ”¥ æ–°å¢: SKU å»é‡æª¢æŸ¥
                if sku in seen_skus:
                    skipped_count += 1
                    print(f"    è·³éé‡è¤‡ SKU: {sku}")
                    continue

                # æå–å•†å“åç¨±
                name_tag = block.select_one(".product-name")
                name = name_tag.text.strip() if name_tag else ""

                # æå–åƒ¹æ ¼
                price_tag = block.select_one(".price")
                price = price_tag.text.strip() if price_tag else ""

                # æå–åœ–ç‰‡URL
                img_tag = block.select_one("img")
                image_url = img_tag.get("src", "") if img_tag else ""

                if sku and name:
                    items.append(
                        {
                            "sku": sku,
                            "name": name,
                            "price": price,
                            "image_url": image_url,
                        }
                    )
                    seen_skus.add(sku)  # ğŸ”¥ è¨˜éŒ„å·²çˆ¬å–çš„ SKU

            except Exception as e:
                print(f"è™•ç†å•†å“å€å¡Šå¤±æ•—: {e}")
                continue

        if skipped_count > 0:
            print(f"    (è·³é {skipped_count} ç­†é‡è¤‡å•†å“)")
        print(f"æˆåŠŸçˆ¬å– {len(items)} ç­†å•†å“")

    except Exception as e:
        print(f"çˆ¬å–é é¢å¤±æ•—: {e}")

    return items


def extract_basic_info(items: List[Dict]) -> pd.DataFrame:
    """
    å¾å•†å“åç¨±ä¸­æå–åŸºæœ¬è³‡è¨Š (gender, category, clothing_type, length)

    Args:
        items: åŸå§‹å•†å“è³‡æ–™åˆ—è¡¨

    Returns:
        åŒ…å«é¡å¤–æ¬„ä½çš„ DataFrame
    """
    df = pd.DataFrame(items)

    # æ€§åˆ¥åˆ¤æ–·è¦å‰‡
    def extract_gender(name: str) -> str:
        if "å¥³" in name or "å¥³æ€§" in name or "å¥³å£«" in name or "å¥³è£" in name:
            return "å¥³"
        elif (
            "ç”·" in name or "ç”·æ€§" in name or "ç”·å£«" in name or "ç”·è£" in name
        ):
            return "ç”·"
        return "-"

    # æœè£é¡å‹åˆ¤æ–·
    def extract_clothing_type(name: str) -> str:
        if any(
            x in name for x in ["Tæ¤", "ä¸Šè¡£", "è¥¯è¡«", "å¤–å¥—", "è¡›è¡£", "POLO"]
        ):
            return "ä¸Šè¡£"
        elif any(x in name for x in ["è¤²", "è£™", "çŸ­è¤²", "ä¹åˆ†è¤²"]):
            return "ä¸‹èº«"
        return "-"

    # é¡åˆ¥ç´°åˆ†
    def extract_category(name: str) -> str:
        if "Tæ¤" in name:
            return "å¥³è£Tæ¤ä¸Šè¡£" if "å¥³" in name else "ç”·è£Tæ¤ä¸Šè¡£"
        elif "è¥¯è¡«" in name:
            return "å¥³è£è¥¯è¡«" if "å¥³" in name else "ç”·è£è¥¯è¡«"
        elif "ç‰›ä»”è¤²" in name:
            return "å¥³è£ç‰›ä»”è¤²" if "å¥³" in name else "ç”·è£ç‰›ä»”è¤²"
        elif "é•·è¤²" in name:
            return "å¥³è£é•·è¤²" if "å¥³" in name else "ç”·è£é•·è¤²"
        return "-"

    # é•·åº¦åˆ¤æ–·
    def extract_length(name: str) -> str:
        if any(x in name for x in ["çŸ­è¢–", "çŸ­ç‰ˆ", "ç„¡è¢–", "äº”åˆ†è¢–", "çŸ­è¤²"]):
            return "çŸ­"
        elif any(x in name for x in ["é•·è¢–", "é•·ç‰ˆ", "é•·è¤²", "ä¹åˆ†"]):
            return "é•·"
        return "-"

    # æ‡‰ç”¨æå–å‡½æ•¸
    df["gender"] = df["name"].apply(extract_gender)
    df["category"] = df["name"].apply(extract_category)
    df["clothing_type"] = df["name"].apply(extract_clothing_type)
    df["length"] = df["name"].apply(extract_length)

    return df


def main():
    """ä¸»ç¨‹å¼æµç¨‹"""
    print("=" * 80)
    print("ğŸ•·ï¸  UNIQLO å•†å“çˆ¬èŸ²")
    print("=" * 80)

    # æ–¹æ³•1: å¦‚æœä½ æœ‰ç¾æˆçš„å•†å“åˆ—è¡¨CSV (ä¾‹å¦‚å¾ç¶²ç«™APIç²å–)
    # å¯ä»¥ç›´æ¥è®€å–ä¸¦è™•ç†
    try:
        # å‡è¨­å·²æœ‰åˆæ­¥çˆ¬å–çš„è³‡æ–™
        raw_file = "init/uniqlo_175.csv"
        print(f"\nè®€å–ç¾æœ‰è³‡æ–™: {raw_file}")
        df = pd.read_csv(raw_file)
        print(f"âœ… è®€å– {len(df)} ç­†å•†å“")

    except FileNotFoundError:
        # æ–¹æ³•2: å¯¦éš›çˆ¬å– (éœ€æ ¹æ“šç¶²ç«™çµæ§‹èª¿æ•´)
        print("\né–‹å§‹çˆ¬å– UNIQLO å•†å“...")

        # å®šç¾©è¦çˆ¬å–çš„é¡åˆ¥URL
        categories = [
            f"{BASE_URL}/women/tops",
            f"{BASE_URL}/women/bottoms",
            f"{BASE_URL}/men/tops",
            f"{BASE_URL}/men/bottoms",
        ]

        all_items = []
        seen_skus = set()  # ğŸ”¥ æ–°å¢: ç”¨æ–¼å…¨åŸŸå»é‡

        for cat_url in categories:
            print(f"\nçˆ¬å–é¡åˆ¥: {cat_url}")
            items = crawl_category_page(
                cat_url, max_items=50, seen_skus=seen_skus
            )
            all_items.extend(items)
            time.sleep(2)  # é¿å…è«‹æ±‚éå¿«

        print(f"\nâœ… ç¸½å…±çˆ¬å– {len(all_items)} ç­†ç¨ç«‹å•†å“")
        print(f"   (å»é‡å¾Œï¼ŒåŸå§‹å¯èƒ½æ›´å¤š)")

        df = pd.DataFrame(all_items)
        print(f"\nâœ… DataFrame åŒ…å« {len(df)} ç­†å•†å“")

        # å„²å­˜åŸå§‹è³‡æ–™
        output_file = "init/uniqlo_raw.csv"
        df.to_csv(output_file, index=False, encoding="utf-8")
        print(f"âœ… åŸå§‹è³‡æ–™å·²å„²å­˜: {output_file}")

    # æå–åŸºæœ¬è³‡è¨Š
    print("\n" + "=" * 80)
    print("ğŸ“ å¾å•†å“åç¨±æå–åŸºæœ¬è³‡è¨Š")
    print("=" * 80)

    df_processed = extract_basic_info(df.to_dict("records"))

    # é¡¯ç¤ºçµ±è¨ˆ
    print(f"\næ€§åˆ¥åˆ†å¸ƒ:")
    print(df_processed["gender"].value_counts())
    print(f"\næœè£é¡å‹åˆ†å¸ƒ:")
    print(df_processed["clothing_type"].value_counts())

    # å„²å­˜è™•ç†å¾Œçš„è³‡æ–™
    output_file = "init/uniqlo_175.csv"
    df_processed.to_csv(output_file, index=False, encoding="utf-8")
    print(f"\nâœ… è™•ç†å¾Œè³‡æ–™å·²å„²å­˜: {output_file}")
    print(f"   æ¬„ä½: {', '.join(df_processed.columns)}")


if __name__ == "__main__":
    main()
