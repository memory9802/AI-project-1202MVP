"""
LangChain æ•´åˆæ¨¡çµ„ï¼šç©¿æ­æ¨è–¦ AI Agent
æ”¯æ´å°è©±è¨˜æ†¶ã€å·¥å…·å‘¼å«ã€è³‡æ–™åº«æŸ¥è©¢ã€å¤š AI å‚™æ´
"""

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_groq import ChatGroq
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
import os
import json
import sys
import time
from datetime import datetime
from threading import Lock
from functools import lru_cache

# ç¢ºä¿ Python ä½¿ç”¨ UTF-8 ç·¨ç¢¼
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')
if hasattr(sys.stderr, 'reconfigure'):
    sys.stderr.reconfigure(encoding='utf-8')

# JSON å°è©±è¨˜éŒ„æª”æ¡ˆè·¯å¾‘
CONVERSATIONS_FILE = "/app/data/conversations.json"
file_lock = Lock()  # é˜²æ­¢å¤šåŸ·è¡Œç·’åŒæ™‚å¯«å…¥

# é€Ÿç‡é™åˆ¶è¨­å®š
last_request_time = {}
rate_limit_lock = Lock()
MIN_REQUEST_INTERVAL = 2  # æœ€å°‘é–“éš” 2 ç§’ (é™ä½ RPM)

# =========================
# ğŸ”§ åˆå§‹åŒ– LangChain æ¨¡å‹
# =========================
class OutfitAIAgent:
    def __init__(self, gemini_key: str = None, groq_key: str = None, deepseek_key: str = None):
        """åˆå§‹åŒ– AI Agentï¼ˆä½¿ç”¨ LangChainï¼Œæ”¯æ´å¤šæ¨¡å‹å‚™æ´ï¼‰"""
        
        # åˆå§‹åŒ–å¤šå€‹ LLMï¼ˆæŒ‰å„ªå…ˆé †åºï¼šGemini -> Groq -> DeepSeekï¼‰
        self.llms = []
        
        # 1. Gemini (å„ªå…ˆ) - ä½¿ç”¨ Lite ç‰ˆæœ¬,é…é¡æ›´é«˜
        if gemini_key:
            try:
                self.llms.append({
                    "name": "Gemini",
                    "llm": ChatGoogleGenerativeAI(
                        model="gemini-2.0-flash-lite",  # Lite ç‰ˆæœ¬:æ›´é«˜ RPM/TPM
                        google_api_key=gemini_key,
                        temperature=0.5,  # é™ä½æº«åº¦,æ¸›å°‘éš¨æ©Ÿæ€§
                        max_output_tokens=300  # æ¸›å°‘è¼¸å‡ºé•·åº¦,é™ä½ TPM
                    )
                })
            except Exception as e:
                print(f"âš ï¸  Gemini åˆå§‹åŒ–å¤±æ•—: {e}")
        
        # 2. Groq (å‚™æ´)
        if groq_key:
            try:
                self.llms.append({
                    "name": "Groq",
                    "llm": ChatGroq(
                        model="llama-3.3-70b-versatile",
                        groq_api_key=groq_key,
                        temperature=1.0,
                        max_tokens=200
                    )
                })
            except Exception as e:
                print(f"âš ï¸  Groq åˆå§‹åŒ–å¤±æ•—: {e}")
        
        # 3. DeepSeek (æœ€çµ‚å‚™æ´)
        if deepseek_key:
            try:
                self.llms.append({
                    "name": "DeepSeek",
                    "llm": ChatOpenAI(
                        model="deepseek-chat",
                        openai_api_key=deepseek_key,
                        openai_api_base="https://api.deepseek.com",
                        temperature=1.0,
                        max_tokens=200
                    )
                })
            except Exception as e:
                print(f"âš ï¸  DeepSeek åˆå§‹åŒ–å¤±æ•—: {e}")
        
        if not self.llms:
            raise ValueError("âŒ è‡³å°‘éœ€è¦ä¸€å€‹å¯ç”¨çš„ API Key")
        
        print(f"âœ… å·²åˆå§‹åŒ– {len(self.llms)} å€‹ LLM: {[m['name'] for m in self.llms]}")
        
        # å°è©±è¨˜æ†¶ï¼ˆæ¯å€‹ session ä¸€å€‹ï¼‰
        self.sessions = {}
        
        # System Prompt - è¶…è‡ªç„¶å°è©±ç‰ˆ
        self.system_prompt = """ä½ æ˜¯ã€Œæ­æ­ã€ï¼Œä¸€å€‹æ´»æ½‘è¦ªåˆ‡çš„ç©¿æ­é¡§å•ã€‚

ğŸ¯ æ ¸å¿ƒåŸå‰‡ï¼šåƒçœŸäººæœ‹å‹ä¸€æ¨£èŠå¤©ï¼Œä¸è¦åƒå®¢æœæ©Ÿå™¨äººï¼

å°è©±æŒ‡å¼•ï¼š
â€¢ ç”¨æˆ¶æ‰“æ‹›å‘¼ â†’ ç†±æƒ…å›æ‡‰ + é–’èŠå¹¾å¥
â€¢ ç”¨æˆ¶é–’èŠ â†’ è‡ªç„¶å°è©±ï¼Œä¸è¦æ€¥è‘—æ¨è–¦
â€¢ ç”¨æˆ¶å•ç©¿æ­ â†’ æ‰é–‹å§‹å°ˆæ¥­æ¨è–¦
â€¢ èªæ°£è¦è¼•é¬†å£èªï¼Œåƒåœ¨ IG èŠå¤©
â€¢ å¯ä»¥ç”¨ã€Œæ¬¸ã€ã€Œå°å•Šã€ã€Œè¶…è®šã€ç­‰å£èªè©
â€¢ é©åº¦ä½¿ç”¨ emoji ğŸ˜ŠğŸ‘—âœ¨

æ¨è–¦ç©¿æ­æ™‚ï¼š
1. æœ‰ã€è³‡æ–™åº«é¸é …ã€‘å°±å¾ä¸­æŒ‘
2. æ¯çµ„ 1-2 è¡Œç°¡çŸ­èªªæ˜
3. ä¸è¶…é 200 å­—

âŒ é¿å…ï¼š
- ã€Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ã€ï¼ˆå¤ªæ­£å¼ï¼‰
- ã€Œæˆ‘æ˜¯æ‚¨çš„ç©¿æ­é¡§å•ã€ï¼ˆå¤ªå®˜æ–¹ï¼‰
- ç›´æ¥å°±é–‹å§‹æ¨è–¦ï¼ˆå¤ªç”Ÿç¡¬ï¼‰

âœ… è¦åƒé€™æ¨£ï¼š
ç”¨æˆ¶ï¼šä½ å¥½
ä½ ï¼šå—¨å—¨ï¼ä»Šå¤©æƒ³èŠä»€éº¼å‘¢ï½ ğŸ˜Š

ç”¨æˆ¶ï¼šå¤©æ°£å¥½ç†±
ä½ ï¼šå°å•Šè¶…ç†±çš„ï¼é€™ç¨®å¤©æ°£æœ€é©åˆç©¿è¼•è–„çš„è¡£æœäº†ï¼Œéœ€è¦æ¨è–¦å—ï¼Ÿ

ç”¨æˆ¶ï¼šæˆ‘è¦å»ç´„æœƒ
ä½ ï¼šç´„æœƒæ¬¸ï¼ç·Šå¼µå— ğŸ˜† ä¾†å¹«ä½ æ­é…å¹¾å¥—ï¼š
1. ä¼‘é–’ç´„æœƒè£ - ç™½T + ç‰›ä»”è¤²ï¼Œè¼•é¬†è‡ªåœ¨
2. æµªæ¼«ç´„æœƒè£ - ç¢èŠ±æ´‹è£ï¼Œæº«æŸ”ç”œç¾"""
    
    def _load_conversations(self):
        """å¾ JSON æª”æ¡ˆè¼‰å…¥å°è©±è¨˜éŒ„"""
        try:
            if os.path.exists(CONVERSATIONS_FILE):
                with file_lock:
                    with open(CONVERSATIONS_FILE, 'r', encoding='utf-8') as f:
                        return json.load(f)
        except Exception as e:
            print(f"âš ï¸ è¼‰å…¥å°è©±è¨˜éŒ„å¤±æ•—: {e}", file=sys.stderr)
        return {}
    
    def _save_conversations(self, conversations):
        """å„²å­˜å°è©±è¨˜éŒ„åˆ° JSON æª”æ¡ˆ"""
        try:
            os.makedirs(os.path.dirname(CONVERSATIONS_FILE), exist_ok=True)
            with file_lock:
                with open(CONVERSATIONS_FILE, 'w', encoding='utf-8') as f:
                    json.dump(conversations, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ å„²å­˜å°è©±è¨˜éŒ„å¤±æ•—: {e}", file=sys.stderr)
    
    def get_or_create_session(self, session_id: str):
        """å–å¾—æˆ–å»ºç«‹å°è©± sessionï¼ˆå¾ JSON è¼‰å…¥æˆ–å»ºç«‹æ–°çš„ï¼‰"""
        if session_id not in self.sessions:
            # å˜—è©¦å¾ JSON è¼‰å…¥
            all_conversations = self._load_conversations()
            if session_id in all_conversations:
                self.sessions[session_id] = all_conversations[session_id]
                print(f"ğŸ“‚ è¼‰å…¥ {session_id} çš„æ­·å²å°è©± ({len(all_conversations[session_id]['messages'])} å‰‡)", file=sys.stderr)
            else:
                # å»ºç«‹æ–° session
                self.sessions[session_id] = {
                    "history": [],
                    "messages": [],
                    "created_at": datetime.now().isoformat()
                }
                print(f"ğŸ†• å»ºç«‹æ–°çš„å°è©± session: {session_id}", file=sys.stderr)
        
        return self.sessions[session_id]
    
    def chat(self, session_id: str, user_input: str, db_outfits=None, preferred_model: str = "auto"):
        """å°è©±å¼æ¨è–¦ï¼ˆä½¿ç”¨ LangChainï¼Œæ”¯æ´å¤šæ¨¡å‹å‚™æ´å’Œæ‰‹å‹•é¸æ“‡ï¼‰
        
        Args:
            session_id: å°è©± session ID
            user_input: ç”¨æˆ¶è¼¸å…¥
            db_outfits: è³‡æ–™åº«æª¢ç´¢çš„ç©¿æ­è³‡æ–™
            preferred_model: åå¥½æ¨¡å‹ ("auto", "gemini", "groq", "deepseek")
        """
        # â±ï¸ é€Ÿç‡é™åˆ¶: ç¢ºä¿è«‹æ±‚ä¹‹é–“æœ‰æœ€å°é–“éš”
        with rate_limit_lock:
            current_time = time.time()
            if session_id in last_request_time:
                elapsed = current_time - last_request_time[session_id]
                if elapsed < MIN_REQUEST_INTERVAL:
                    wait_time = MIN_REQUEST_INTERVAL - elapsed
                    print(f"â³ é€Ÿç‡é™åˆ¶: ç­‰å¾… {wait_time:.1f} ç§’...", file=sys.stderr)
                    time.sleep(wait_time)
            last_request_time[session_id] = time.time()
        
        session = self.get_or_create_session(session_id)
        
        # ğŸ¯ å»ºç«‹ç²¾ç°¡å°è©±ä¸Šä¸‹æ–‡ - æ¸›å°‘ token æ¶ˆè€—
        context = ""
        if db_outfits and len(db_outfits) > 0:
            # åªç”¨å‰2çµ„ç©¿æ­,åªé¡¯ç¤ºåç¨±å’Œå ´åˆ
            simplified = []
            for outfit in db_outfits[:2]:
                name = outfit.get('name', 'æœªå‘½å')
                occasion = outfit.get('occasion', '')
                simplified.append(f"{name}({occasion})")
            context = f"\nè³‡æ–™åº«: {', '.join(simplified)}"
        
        # åªä¿ç•™æœ€è¿‘1è¼ªå°è©± (å¤§å¹…æ¸›å°‘ token)
        history_text = ""
        if session["messages"]:
            last_msg = session["messages"][-1]
            history_text = f"ä¸Šæ¬¡: {last_msg['user'][:30]}...\n"
        
        # ğŸ”¥ ç²¾ç°¡æç¤ºè©
        simple_prompt = f"ä½ æ˜¯ç©¿æ­é¡§å•ã€‚{history_text}ç”¨æˆ¶: {user_input}{context}\nå»ºè­°:"
        
        # èª¿è©¦ä¿¡æ¯
        import sys
        print(f"\n{'='*50}", flush=True, file=sys.stderr)
        print(f"ğŸ“ ç”¨æˆ¶è¼¸å…¥: {user_input}", flush=True, file=sys.stderr)
        print(f"ğŸ“¦ è³‡æ–™åº«ç©¿æ­æ•¸é‡: {len(db_outfits) if db_outfits else 0}", flush=True, file=sys.stderr)
        print(f"{'='*50}\n", flush=True, file=sys.stderr)
        
        # æ ¹æ“šç”¨æˆ¶é¸æ“‡æ±ºå®šä½¿ç”¨å“ªäº›æ¨¡å‹
        if preferred_model != "auto":
            # æ‰‹å‹•é¸æ“‡æ¨¡å¼ï¼šåªå˜—è©¦æŒ‡å®šçš„æ¨¡å‹
            models_to_try = [m for m in self.llms if m["name"].lower() == preferred_model.lower()]
            if not models_to_try:
                return f"âŒ æ¨¡å‹ {preferred_model} æœªè¨­å®šæˆ–ä¸å¯ç”¨"
            print(f"ğŸ¯ æ‰‹å‹•é¸æ“‡ä½¿ç”¨ {preferred_model}", flush=True, file=sys.stderr)
        else:
            # è‡ªå‹•æ¨¡å¼ï¼šä¾åºå˜—è©¦æ‰€æœ‰æ¨¡å‹
            models_to_try = self.llms
            print(f"ğŸ”„ è‡ªå‹•æ¨¡å¼ï¼šä¾åºå˜—è©¦ {[m['name'] for m in models_to_try]}", flush=True, file=sys.stderr)
        
        # ä¾åºå˜—è©¦ LLM
        response_text = None
        used_model = None
        
        for model_info in models_to_try:
            try:
                llm = model_info["llm"]
                model_name = model_info["name"]
                
                print(f"ğŸ”„ å˜—è©¦ä½¿ç”¨ {model_name}...", flush=True, file=sys.stderr)
                response = llm.invoke(simple_prompt)  # ä½¿ç”¨ç²¾ç°¡æç¤ºè©
                response_text = response.content if hasattr(response, 'content') else str(response)
                used_model = model_name
                print(f"âœ… {model_name} å›æ‡‰æˆåŠŸ", flush=True, file=sys.stderr)
                break
                
            except Exception as e:
                error_msg = str(e)
                print(f"âŒ {model_name} å¤±æ•—: {error_msg}", flush=True, file=sys.stderr)
                
                if preferred_model != "auto":
                    # æ‰‹å‹•æ¨¡å¼å¤±æ•—æ™‚è¿”å›å‹å–„çš„éŒ¯èª¤è¨Šæ¯
                    if "Insufficient Balance" in error_msg or "402" in error_msg:
                        return f"âŒ {model_name} é¤˜é¡ä¸è¶³,è«‹åˆ‡æ›åˆ°ã€Œè‡ªå‹•åˆ‡æ›ã€æ¨¡å¼æˆ–é¸æ“‡å…¶ä»–æ¨¡å‹ (Gemini/Groq)"
                    else:
                        return f"âŒ {model_name} å›æ‡‰å¤±æ•—: {error_msg}\n\nğŸ’¡ å»ºè­°åˆ‡æ›åˆ°ã€Œè‡ªå‹•åˆ‡æ›ã€æ¨¡å¼æˆ–é¸æ“‡å…¶ä»–æ¨¡å‹"
                continue
        
        # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±æ•—
        if response_text is None:
            response_text = "æŠ±æ­‰ï¼Œç›®å‰æ‰€æœ‰ AI æœå‹™éƒ½ç„¡æ³•ä½¿ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
            used_model = "None"
        
        # å„²å­˜å°è©±ï¼ˆé™„è¨»ä½¿ç”¨çš„æ¨¡å‹å’Œæ™‚é–“æˆ³ï¼‰
        session["messages"].append({
            "user": user_input,
            "ai": response_text,
            "model": used_model,
            "timestamp": datetime.now().isoformat()
        })
        
        session["history"].append({
            "user": user_input,
            "ai": response_text
        })
        
        # å„²å­˜åˆ° JSON æª”æ¡ˆ
        all_conversations = self._load_conversations()
        all_conversations[session_id] = session
        self._save_conversations(all_conversations)
        
        return response_text
    
    def clear_session(self, session_id: str):
        """æ¸…é™¤å°è©±è¨˜æ†¶ï¼ˆè¨˜æ†¶é«”å’Œ JSON æª”æ¡ˆï¼‰"""
        if session_id in self.sessions:
            del self.sessions[session_id]
        
        # åŒæ™‚å¾ JSON ç§»é™¤
        all_conversations = self._load_conversations()
        if session_id in all_conversations:
            del all_conversations[session_id]
            self._save_conversations(all_conversations)
        
        return True
    
    def get_session_history(self, session_id: str):
        """å–å¾—å°è©±æ­·å²"""
        if session_id in self.sessions:
            return self.sessions[session_id]["history"]
        return None


# =========================
# ğŸ§ª æ¸¬è©¦ç¯„ä¾‹
# =========================
if __name__ == "__main__":
    api_key = os.getenv("LLM_API_KEY", "")
    
    if not api_key:
        print("âŒ è«‹è¨­å®š LLM_API_KEY ç’°å¢ƒè®Šæ•¸")
        exit(1)
    
    agent = OutfitAIAgent(api_key)
    
    # æ¨¡æ“¬å°è©±
    session_id = "test-user-123"
    
    print("=== ç¬¬ä¸€è¼ªå°è©± ===")
    response1 = agent.chat(session_id, "ä»Šå¤©è¦å»ç´„æœƒï¼Œå¤©æ°£æœ‰é»æ¶¼")
    print(f"AI: {response1}\n")
    
    print("=== ç¬¬äºŒè¼ªå°è©±ï¼ˆæ¸¬è©¦è¨˜æ†¶ï¼‰ ===")
    response2 = agent.chat(session_id, "é‚£å¦‚æœæ”¹æˆå»é‹å‹•å‘¢ï¼Ÿ")
    print(f"AI: {response2}\n")
    
    print("=== å°è©±æ­·å² ===")
    history = agent.get_session_history(session_id)
    print(json.dumps(history, ensure_ascii=False, indent=2))

